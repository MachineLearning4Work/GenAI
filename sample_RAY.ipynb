{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxQT1xYcjM13"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XSB22cqfjNWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "=================================================\n",
        "We have this function as you can see it accept a single PDF path and then\n",
        "convert it into collection of images per page and then\n",
        "- read pdf text for all pages and save it into sub_pdf_page_text list\n",
        "and also list of all conveted images into sub_images_path LIST\n",
        "\n",
        "and then in a for loop :\n",
        "for count, (image_path, pdf_text) in enumerate(zip(sub_images_path, sub_pdf_page_text)):\n",
        "\n",
        "  as you can see call OCR function \"run_image_text_extraction\"\n",
        "  per page\n",
        "  and then we update\n",
        "  inputs_payload per page\n",
        "  and then send it per page to\n",
        "  ContractcleanPDFCrew().crew().kickoff(inputs=inputs_payload)\n",
        "\n",
        "  as a result of this\n",
        "  we have some text files a folder and then we merge it\n",
        "  merge_txt_files(file_folder)\n",
        "\n",
        "  I wpuld like to accelarate the procedure in for loop with using ray or multu threading or multi processing\n",
        "\n",
        "  ==============================================\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "from slugify import slugify\n",
        "\n",
        "def kickoff_ray(file_path, output_folder='output/images'):\n",
        "    inputs_payload = {'pdf_path': file_path}\n",
        "\n",
        "    # Convert PDF to JPG\n",
        "    sub_images_list_with_metaData = pdf2jpg.convert_pdf2jpg(\n",
        "        file_path, output_folder, pages=\"ALL\"\n",
        "    )\n",
        "\n",
        "    # Extract text from PDF\n",
        "    reader_pdf = PdfReader(file_path)\n",
        "    sub_pdf_page_text = [page.extract_text() for page in reader_pdf.pages]\n",
        "\n",
        "    # Extract image paths\n",
        "    sub_images_path = sub_images_list_with_metaData[0]['output_jpgfiles']\n",
        "    sub_images_list_count = len(sub_images_path)\n",
        "    folder_to_delete = os.path.dirname(sub_images_path[0])\n",
        "\n",
        "    print(\"folder_to_delete\\n\", folder_to_delete)\n",
        "\n",
        "    # Check if the image count matches PDF page count\n",
        "    if len(sub_images_path) != len(sub_pdf_page_text):\n",
        "        raise ValueError(\"The image paths and PDF texts lists must have the same length !!!\")\n",
        "    else:\n",
        "        print(\"The same Length for both OCR Sub-Images and PDF Sub-Pages :\\n\")\n",
        "\n",
        "    # Loop through images and PDF text\n",
        "    for count, (image_path, pdf_text) in enumerate(zip(sub_images_path, sub_pdf_page_text)):\n",
        "        print(f\"\\nProcessing Pair {count+1}/{len(sub_images_path)}\")\n",
        "        extracted_text_ocr = run_image_text_extraction(image_path)\n",
        "        print(f\"Image : {image_path}\")\n",
        "\n",
        "        # Extract base file name and create folder name\n",
        "        file_name = os.path.splitext(os.path.basename(inputs_payload['pdf_path']))[0]\n",
        "        file_folder = slugify_filename(file_name)\n",
        "\n",
        "        print(f\"Filename is {file_name}\")\n",
        "        print(f\"File Folder is {file_folder}\")\n",
        "\n",
        "        # Create the directory for JSON parts\n",
        "        print(f\"Creating output directory: {file_folder}\")\n",
        "        Path(f\"output/json/{file_folder}\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        print(f\"Text Length : {len(pdf_text)} characters\\n\")\n",
        "\n",
        "        # Update the inputs payload with extracted data\n",
        "        inputs_payload.update({\n",
        "            'image_path': image_path,\n",
        "            'file_name': file_name,\n",
        "            'file_folder': file_folder,\n",
        "            'page_number': count + 1,\n",
        "            'pdf_text': pdf_text,\n",
        "            'ocr_text': extracted_text_ocr\n",
        "        })\n",
        "\n",
        "        # Kick off processing crew\n",
        "        print(f\"\\nInput PAYLOAD Keys : Kicking off inputs : {inputs_payload.keys()}\")\n",
        "        print(\"======================\")\n",
        "        ContractcleanPDFCrew().crew().kickoff(inputs=inputs_payload)\n",
        "\n",
        "    # Merge all text files for the contract\n",
        "    print(\"Merging pages Per input Contract file; \\n\")\n",
        "    merge_txt_files(file_folder)\n",
        "    clean_text_path=os.path.join(.........)\n",
        "    input_payload_parsing ={'clean_text_path': clean_text_path}\n",
        "    contractanalysis crew().crew().kickoff(inputs- input_payload_parsing)\n",
        "\n"
      ],
      "metadata": {
        "id": "T_M7jlmvjNbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "from pathlib import Path\n",
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "from slugify import slugify\n",
        "\n",
        "ray.init(ignore_reinit_error=True)\n",
        "\n",
        "# Your OCR + crew function wrapped in a Ray task\n",
        "@ray.remote\n",
        "def process_page_remote(inputs_payload_base, image_path, pdf_text, count):\n",
        "    from your_module import run_image_text_extraction, ContractcleanPDFCrew  # import inside Ray task\n",
        "    from your_module import slugify_filename  # helper if not already global\n",
        "\n",
        "    extracted_text_ocr = run_image_text_extraction(image_path)\n",
        "\n",
        "    file_name = os.path.splitext(os.path.basename(inputs_payload_base['pdf_path']))[0]\n",
        "    file_folder = slugify_filename(file_name)\n",
        "    Path(f\"output/json/{file_folder}\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Prepare per-page payload\n",
        "    inputs_payload = inputs_payload_base.copy()\n",
        "    inputs_payload.update({\n",
        "        'image_path': image_path,\n",
        "        'file_name': file_name,\n",
        "        'file_folder': file_folder,\n",
        "        'page_number': count + 1,\n",
        "        'pdf_text': pdf_text,\n",
        "        'ocr_text': extracted_text_ocr\n",
        "    })\n",
        "\n",
        "    ContractcleanPDFCrew().crew().kickoff(inputs=inputs_payload)\n",
        "    return file_folder  # return file_folder for merging step later\n"
      ],
      "metadata": {
        "id": "JvBtNPKvq-eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kickoff_ray(file_path, output_folder='output/images'):\n",
        "    inputs_payload = {'pdf_path': file_path}\n",
        "\n",
        "    sub_images_list_with_metaData = pdf2jpg.convert_pdf2jpg(file_path, output_folder, pages=\"ALL\")\n",
        "    reader_pdf = PdfReader(file_path)\n",
        "    sub_pdf_page_text = [page.extract_text() for page in reader_pdf.pages]\n",
        "    sub_images_path = sub_images_list_with_metaData[0]['output_jpgfiles']\n",
        "\n",
        "    if len(sub_images_path) != len(sub_pdf_page_text):\n",
        "        raise ValueError(\"Image and PDF page counts mismatch!\")\n",
        "\n",
        "    # Launch Ray tasks for each page\n",
        "    futures = [\n",
        "        process_page_remote.remote(inputs_payload, image_path, pdf_text, count)\n",
        "        for count, (image_path, pdf_text) in enumerate(zip(sub_images_path, sub_pdf_page_text))\n",
        "    ]\n",
        "\n",
        "    # Wait for all Ray tasks to complete and get file folder name\n",
        "    file_folder_list = ray.get(futures)\n",
        "    file_folder = file_folder_list[0]  # all should be the same\n",
        "\n",
        "    # Merge results after all parallel tasks\n",
        "    print(\"Merging pages per input contract file;\")\n",
        "    merge_txt_files(file_folder)\n",
        "\n",
        "    clean_text_path = os.path.join(\"output/json\", file_folder, \"merged.txt\")\n",
        "    input_payload_parsing = {'clean_text_path': clean_text_path}\n",
        "    contractanalysiscrew().crew().kickoff(inputs=input_payload_parsing)\n"
      ],
      "metadata": {
        "id": "RB8ixlx3rIfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from PyPDF2 import PdfReader\n",
        "from slugify import slugify\n",
        "import ray\n",
        "\n",
        "# Initialize Ray\n",
        "ray.init(ignore_reinit_error=True)\n",
        "\n",
        "# === Dummy Replacements: Replace with your actual implementations === #\n",
        "def pdf2jpg_convert_dummy(file_path, output_folder, pages=\"ALL\"):\n",
        "    # Simulate conversion, return structure similar to pdf2jpg\n",
        "    return [{\n",
        "        'output_jpgfiles': [f\"{output_folder}/page_{i}.jpg\" for i in range(3)]\n",
        "    }]\n",
        "\n",
        "def run_image_text_extraction(image_path):\n",
        "    # Simulated OCR function\n",
        "    return f\"Extracted OCR text from {image_path}\"\n",
        "\n",
        "class ContractcleanPDFCrew:\n",
        "    def crew(self):\n",
        "        return self\n",
        "    def kickoff(self, inputs):\n",
        "        print(f\"[Crew] Kicked off with inputs: {list(inputs.keys())}\")\n",
        "\n",
        "class contractanalysiscrew:\n",
        "    def crew(self):\n",
        "        return self\n",
        "    def kickoff(self, inputs):\n",
        "        print(f\"[Analysis] Analyzing: {inputs['clean_text_path']}\")\n",
        "\n",
        "def merge_txt_files(folder):\n",
        "    # Simulated merge function\n",
        "    print(f\"[Merge] Merging text files in folder: {folder}\")\n",
        "# ===================================================================== #\n",
        "\n",
        "# Helper to slugify filename\n",
        "def slugify_filename(name):\n",
        "    return slugify(name)\n",
        "\n",
        "# Ray remote task to process a single page\n",
        "@ray.remote\n",
        "def process_page_remote(inputs_payload_base, image_path, pdf_text, count):\n",
        "    extracted_text_ocr = run_image_text_extraction(image_path)\n",
        "\n",
        "    file_name = os.path.splitext(os.path.basename(inputs_payload_base['pdf_path']))[0]\n",
        "    file_folder = slugify_filename(file_name)\n",
        "    Path(f\"output/json/{file_folder}\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    inputs_payload = inputs_payload_base.copy()\n",
        "    inputs_payload.update({\n",
        "        'image_path': image_path,\n",
        "        'file_name': file_name,\n",
        "        'file_folder': file_folder,\n",
        "        'page_number': count + 1,\n",
        "        'pdf_text': pdf_text,\n",
        "        'ocr_text': extracted_text_ocr\n",
        "    })\n",
        "\n",
        "    ContractcleanPDFCrew().crew().kickoff(inputs=inputs_payload)\n",
        "    return file_folder\n",
        "\n",
        "# Main function to kick off processing\n",
        "def kickoff_ray(file_path, output_folder='output/images'):\n",
        "    inputs_payload = {'pdf_path': file_path}\n",
        "\n",
        "    # === Convert PDF to Images ===\n",
        "    sub_images_list_with_metaData = pdf2jpg_convert_dummy(file_path, output_folder)\n",
        "    sub_images_path = sub_images_list_with_metaData[0]['output_jpgfiles']\n",
        "\n",
        "    # === Extract PDF Text ===\n",
        "    reader_pdf = PdfReader(file_path)\n",
        "    sub_pdf_page_text = [page.extract_text() or \"\" for page in reader_pdf.pages]\n",
        "\n",
        "    if len(sub_images_path) != len(sub_pdf_page_text):\n",
        "        raise ValueError(\"Mismatch in image and text lengths\")\n",
        "\n",
        "    # === Launch Ray tasks ===\n",
        "    futures = [\n",
        "        process_page_remote.remote(inputs_payload, img, txt, idx)\n",
        "        for idx, (img, txt) in enumerate(zip(sub_images_path, sub_pdf_page_text))\n",
        "    ]\n",
        "\n",
        "    file_folders = ray.get(futures)\n",
        "    file_folder = file_folders[0]  # all pages share the same folder\n",
        "\n",
        "    # === Post-processing ===\n",
        "    merge_txt_files(file_folder)\n",
        "    clean_text_path = os.path.join(\"output/json\", file_folder, \"merged.txt\")\n",
        "    contractanalysiscrew().crew().kickoff(inputs={'clean_text_path': clean_text_path})\n",
        "\n",
        "# === Run example ===\n",
        "if __name__ == \"__main__\":\n",
        "    test_pdf_path = \"sample_contract.pdf\"\n",
        "    kickoff_ray(test_pdf_path)\n"
      ],
      "metadata": {
        "id": "e9fKkLI3rNy8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}